{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Perform analysis on a piec of document in terms of its words and sentence numbers\n",
    "# numbers of words and number of sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1\n",
    "with open(\"complexAnalysis.txt\",\"r\",encoding='utf-8',errors='ignore') as file:\n",
    "    file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['caprovinces.txt',\n",
       " 'countries.txt',\n",
       " 'isocountries.txt',\n",
       " 'mexstates.txt',\n",
       " 'nationalities.txt',\n",
       " 'uscities.txt',\n",
       " 'usstateabbrev.txt',\n",
       " 'usstates.txt']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gazetteers\n",
    "from nltk import sent_tokenize,word_tokenize  # this allows you to make sentences and words from text file.\n",
    "gazetteers.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abkhazia\n",
      "Afghanistan\n",
      "Akrotiri\n",
      "Akrotiri and Dhekelia\n",
      "Aland\n",
      "Aland Islands\n",
      "Albania\n",
      "Algeria\n",
      "America\n",
      "American Samoa\n",
      "Andorra\n",
      "Angola\n",
      "Anguilla\n",
      "Antigua\n",
      "Antigua and Barbuda\n",
      "Argentina\n",
      "Armenia\n",
      "Aruba\n",
      "Ascension Island\n",
      "Australia\n",
      "Austria\n",
      "Azerbaijan\n",
      "Bahamas\n",
      "Bahrain\n",
      "Bangladesh\n",
      "Barbados\n",
      "Barbuda\n",
      "Belarus\n",
      "Belgium\n",
      "Belize\n",
      "Benin\n",
      "Bermuda\n",
      "Bhutan\n",
      "Bolivia\n",
      "Bosnia\n",
      "Bosnia and Herzegovina\n",
      "Botswana\n",
      "Brazil\n",
      "British Virgin Islands\n",
      "Brunei\n",
      "Bulgaria\n",
      "Burkina Faso\n",
      "Burma\n",
      "Burundi\n",
      "Caicos Islands\n",
      "Cambodia\n",
      "Cameroon\n",
      "Canada\n",
      "Cape Verde\n",
      "Cayman Islands\n",
      "Central African Republic\n",
      "Chad\n",
      "Chile\n",
      "China\n",
      "Christmas Island\n",
      "Cocos\n",
      "Cocos Islands\n",
      "Colombia\n",
      "Comoros\n",
      "Congo\n",
      "Cook Islands\n",
      "Costa Rica\n",
      "Cote d'Ivoire\n",
      "Croatia\n",
      "Cuba\n",
      "Cyprus\n",
      "Czech Republic\n",
      "Democratic Republic of Congo\n",
      "Denmark\n",
      "Dhekelia\n",
      "Djibouti\n",
      "Dominica\n",
      "Dominican Republic\n",
      "East Timor\n",
      "Ecuador\n",
      "Egypt\n",
      "El Salvador\n",
      "England\n",
      "Equatorial Guinea\n",
      "Eritrea\n",
      "Estonia\n",
      "Ethiopia\n",
      "Falkland Islands\n",
      "Faroe Islands\n",
      "Fiji\n",
      "Finland\n",
      "Former Soviet Union\n",
      "Former USSR\n",
      "France\n",
      "French Polynesia\n",
      "Futuna Islands\n",
      "Gabon\n",
      "Gambia\n",
      "Georgia\n",
      "Germany\n",
      "Ghana\n",
      "Gibraltar\n",
      "Greece\n",
      "Greenland\n",
      "Grenada\n",
      "Grenadines\n",
      "Guam\n",
      "Guatemala\n",
      "Guernsey\n",
      "Guinea\n",
      "Guinea-Bissau\n",
      "Guyana\n",
      "Haiti\n",
      "Herzegovina\n",
      "Honduras\n",
      "Hong Kong\n",
      "Hoorn Islands\n",
      "Hungary\n",
      "Iceland\n",
      "India\n",
      "Indonesia\n",
      "Iran\n",
      "Iraq\n",
      "Ireland\n",
      "Isle of Man\n",
      "Israel\n",
      "Italy\n",
      "Jamaica\n",
      "Japan\n",
      "Jersey\n",
      "Jordan\n",
      "Kazakhstan\n",
      "Keeling Islands\n",
      "Kenya\n",
      "Kiribati\n",
      "Korea\n",
      "Kosovo\n",
      "Kuwait\n",
      "Kyrgyzstan\n",
      "Laos\n",
      "Latvia\n",
      "Lebanon\n",
      "Lesotho\n",
      "Liberia\n",
      "Libya\n",
      "Liechtenstein\n",
      "Lithuania\n",
      "Luxembourg\n",
      "Macao\n",
      "Macau\n",
      "Macedonia\n",
      "Madagascar\n",
      "Malawi\n",
      "Malaysia\n",
      "Maldives\n",
      "Mali\n",
      "Malta\n",
      "Marshall Islands\n",
      "Mauritania\n",
      "Mauritius\n",
      "Mayotte\n",
      "Mexico\n",
      "Micronesia\n",
      "Miquelon\n",
      "Moldova\n",
      "Monaco\n",
      "Mongolia\n",
      "Montenegro\n",
      "Montserrat\n",
      "Morocco\n",
      "Mozambique\n",
      "Myanmar\n",
      "Nagorno-Karabakh Republic\n",
      "Namibia\n",
      "Nauru\n",
      "Nepal\n",
      "Netherlands\n",
      "Netherlands Antilles\n",
      "Nevis\n",
      "New Caledonia\n",
      "New Zealand\n",
      "Nicaragua\n",
      "Niger\n",
      "Nigeria\n",
      "Niue\n",
      "Norfolk Island\n",
      "Northern Mariana Islands\n",
      "North Korea\n",
      "Norway\n",
      "Oman\n",
      "Pakistan\n",
      "Palau\n",
      "Palestine\n",
      "Palestinian Territory\n",
      "Panama\n",
      "Papua New Guinea\n",
      "Paraguay\n",
      "People's Republic of China\n",
      "Peru\n",
      "Philippines\n",
      "Pitcairn Islands\n",
      "Poland\n",
      "Portugal\n",
      "Principe\n",
      "Puerto Rico\n",
      "Qatar\n",
      "Romania\n",
      "Russia\n",
      "Rwanda\n",
      "Saint Barthelemy\n",
      "Saint Barts\n",
      "Saint Helena\n",
      "Saint Kitts \n",
      "Saint Kitts and Nevis\n",
      "Saint Lucia\n",
      "Saint Martin\n",
      "Saint Pierre \n",
      "Saint Pierre and Miquelon\n",
      "Saint Vincent\n",
      "Saint Vincent and the Grenadines\n",
      "Samoa\n",
      "San Marino\n",
      "Sao Tome\n",
      "Sao Tome and Principe\n",
      "Saudi Arabia\n",
      "Scotland\n",
      "Senegal\n",
      "Serbia\n",
      "Seychelles\n",
      "Sierra Leone\n",
      "Singapore\n",
      "Slovakia\n",
      "Slovenia\n",
      "Solomon Islands\n",
      "Somalia\n",
      "Somaliland\n",
      "South Africa\n",
      "South Korea\n",
      "South Ossetia\n",
      "Soviet Union\n",
      "Spain\n",
      "Sri Lanka\n",
      "Sudan\n",
      "Suriname\n",
      "Svalbard\n",
      "Swaziland\n",
      "Sweden\n",
      "Switzerland\n",
      "Syria\n",
      "Taiwan\n",
      "Tajikistan\n",
      "Tanzania\n",
      "Thailand\n",
      "Tibet\n",
      "Tobago\n",
      "Togo\n",
      "Tokelau\n",
      "Tonga\n",
      "Transnistria\n",
      "Trinidad\n",
      "Trinidad and Tobago\n",
      "Tristan da Cunha\n",
      "Tunisia\n",
      "Turkey\n",
      "Turkmenistan\n",
      "Turks and Caicos Islands\n",
      "Turks Islands\n",
      "Tuvalu\n",
      "UAE\n",
      "Uganda\n",
      "UK\n",
      "Ukraine\n",
      "United Arab Emirates\n",
      "United Kingdom\n",
      "United States\n",
      "United States Virgin Islands\n",
      "Uruguay\n",
      "US\n",
      "USA\n",
      "USSR\n",
      "US Virgin Islands\n",
      "Uzbekistan\n",
      "Vanuatu\n",
      "Vatican\n",
      "Vatican City\n",
      "Venezuela\n",
      "Vietnam\n",
      "Virgin Islands\n",
      "Wallis and Futuna\n",
      "Wallis Islands\n",
      "Western Sahara\n",
      "Yemen\n",
      "Zambia\n",
      "Zimbabwe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Option2\n",
    "#  This will return the entire text as a string\n",
    "text=gazetteers.raw('countries.txt')\n",
    "print(text)\n",
    "num_chars=len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "403\n",
      "3001\n"
     ]
    }
   ],
   "source": [
    "#  dealing with sentence tokens,words and characters,\n",
    "sentences=nltk.Text(sent_tokenize(text))\n",
    "print(len(sentences))\n",
    "words=nltk.Text(word_tokenize(text))\n",
    "print(len(words))\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "319\n",
      "1467\n",
      "44502\n",
      "2232\n",
      "44024\n",
      "2160\n",
      "32887\n",
      "2004\n",
      "41386\n",
      "1900\n",
      "43979\n",
      "822\n",
      "17256\n",
      "1669\n",
      "43732\n",
      "1332\n",
      "40820\n"
     ]
    }
   ],
   "source": [
    "#  reading all the entire text in corpus.\n",
    "for text in genesis.fileids():\n",
    "    genesis.raw('complexAnalysis.txt')\n",
    "    sentences=nltk.Text(sent_tokenize(genesis.raw(text)))\n",
    "    print(len(sentences))\n",
    "    words=nltk.Text(word_tokenize(genesis.raw(text)))\n",
    "    print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out unique words from word_tokenize\n",
    "def complex_analysis(text):\n",
    "    vocabs={x.lower() for x in word_tokenize(text)}\n",
    "    print(len(vocabs)) # This returns number of unique words\n",
    "    print(num_chars/len(vocabs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307\n",
      "9.775244299674267\n"
     ]
    }
   ],
   "source": [
    "complex_analysis(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit75382811ef8d4425985ed694e71564ee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
